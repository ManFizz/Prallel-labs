# Что такое параллелизм
Параллелизм – это ключевая концепция в области программирования, которая позволяет выполнять несколько задач одновременно, ускоряя общее время выполнения программы. Эта способность становится особенно важной в многозадачных и многопоточных средах, где эффективное использование ресурсов является приоритетом.

# Зачем нужен параллелизм?
1. **Увеличение производительности**
2. **Максимальное использование ресурсов**
3. **Обеспечение отзывчивости**
4. **Разделение задач**

# Основные принципы параллелизма

## Параллелизм на уровне задач
Наиболее распространенным подходом к параллелизму является разделение задач на более мелкие и независимые части. Эти части могут быть выполнены параллельно, что в конечном итоге ускоряет выполнение всей задачи. Примером может служить параллельное выполнение итераций цикла, обработка различных элементов массива, или даже выполнение независимых операций в рамках одной задачи.

## Параллелизм на уровне данных
Другим важным аспектом параллелизма является эффективное управление данными. Разделение данных между потоками или процессами может существенно повысить производительность программы. Однако, необходимо внимательно учитывать синхронизацию доступа к общим данным для предотвращения гонок данных и обеспечения их целостности.

## Многозадачность и многопоточность
Многозадачные и многопоточные системы позволяют выполнять несколько задач или потоков исполнения одновременно. Это может быть реализовано как на уровне операционной системы, так и на уровне прикладного программного обеспечения. Многопоточность часто используется для повышения отзывчивости приложений и эффективного использования многозадачных ресурсов.

# Управление потоками

## Основы работы с потоками
Управление потоками в параллельном программировании является ключевым аспектом для эффективного использования параллелизма. Потоки представляют собой независимые последовательности выполнения, способные выполнять задачи параллельно. В C++, стандартная библиотека предоставляет механизмы для создания и управления потоками, такие как `std::thread`.

Допустим, у нас есть функция, которую мы хотим выполнить в отдельном потоке, и мы используем `std::thread` для создания и запуска этого потока.

```c++
#include <iostream>
#include <thread>

// Пример функции, которую мы будем выполнять в отдельном потоке
void myFunction(int id) {
    std::cout << "Thread " << id << " is running.\n";
}

int main() {
    // Создаем объект std::thread и передаем ему функцию myFunction и ее аргумент
    std::thread thread1(myFunction, 1);

    // Ждем, пока поток завершится
    thread1.join();

    // Второй способ создания и запуска потока в одной строке
    std::thread thread2([](){
        std::cout << "Thread 2 is running.\n";
    });

    // Ждем, пока второй поток завершится
    thread2.join();

    return 0;
}

```

# Deadlock и Race Conditions

## Deadlock

Deadlock (взаимная блокировка) - это ситуация в многозадачной среде, когда два или более потока (или процесса) блокируют друг друга, ожидая освобождения ресурсов, которые они сами удерживают. Это приводит к тому, что все участвующие потоки остаются заблокированными вечно, и программа не может продолжить выполнение.

Пример:
- Поток A удерживает ресурс X и ожидает освобождения ресурса Y.
- Поток B удерживает ресурс Y и ожидает освобождения ресурса X.

В итоге A ждет B, B ждет A, и оба потока остаются заблокированными.

## Race Condition

Race Condition (гонка данных) возникает, когда два или более потока обращаются к общему ресурсу, и хотя бы один из них изменяет его значение. Результат зависит от того, какие операции выполняются в каком порядке, и неопределенность может привести к некорректному поведению программы.

Пример:
- Два потока одновременно читают и модифицируют значение переменной X.
- Поток A читает значение X.
- Поток B читает значение X.
- Поток A изменяет значение X и записывает обратно.
- Поток B изменяет значение X и записывает обратно.

Результат зависит от того, какой из потоков последним завершил запись, и, таким образом, может быть неопределенным.

Обе ситуации могут привести к непредсказуемому поведению программы и являются серьезными проблемами в многозадачных и многопоточных приложениях. Избежание deadlock и race conditions обычно требует правильной синхронизации доступа к общим ресурсам, такой как использование мьютексов, семафоров и других механизмов синхронизации.

## Синхронизация доступа к данным
Синхронизация является критическим аспектом параллельного программирования. Одновременный доступ нескольких потоков к общим данным может привести к гонкам данных и неопределенному поведению программы. Рассмотрим мьютексы `std::mutex`, для обеспечения правильного доступа к общим данным.

В данном случае мы используем мьютекс для защиты вывода в консоль от гонок данных между потоками.
```c++
#include <iostream>
#include <thread>
#include <mutex>

std::mutex myMutex;  // Создаем объект мьютекса

void printMessage(int id) {
    std::lock_guard<std::mutex> lock(myMutex);  // Автоматическое управление блокировкой мьютекса
    std::cout << "Thread " << id << " is running.\n";
}  
// Мьютекс разблокируется автоматически при выходе из области видимости lock_guard

int main() {
    const int numThreads = 3;
    std::thread threads[numThreads];

    for (int i = 0; i < numThreads; ++i) {
        // Каждый поток вызывает функцию printMessage с уникальным идентификатором
        threads[i] = std::thread(printMessage, i + 1);
    }

    for (int i = 0; i < numThreads; ++i) {
        threads[i].join();  // Ожидаем завершения каждого потока
    }

    return 0;
}
```

# Разделение данных между потоками

## Проектирование параллельных структур данных
Для эффективной работы с параллельными вычислениями важно правильно разделять данные между потоками. Рассмотрим принципы проектирования параллельных структур данных, таких как очереди, блокированные очереди `std::queue` и `std::mutex` для обеспечения безопасности работы с данными в многопоточной среде.

Пример использования блокированных очередей (std::queue) и std::mutex для обеспечения безопасности работы с данными в многопоточной среде:
1. Есть производитель `producer`, который добавляет элементы в блокированную очередь `myQueue`.
2. Есть несколько потребителей `consumer`, которые извлекают элементы из очереди. Они ожидают уведомления `dataReady.notify_one()`, что в очереди появились новые данные.
3. Мьютекс `myMutex` используется для синхронизации доступа к общей очереди.
4. Условная переменная `dataReady` используется для уведомления потребителей о наличии новых данных в очереди.
5. Потоки `producer` и `consumer` выполняются параллельно.

```c++
#include <iostream>
#include <queue>
#include <mutex>
#include <thread>
#include <condition_variable>

std::queue<int> myQueue;             // Общая блокированная очередь
std::mutex myMutex;                   // Мьютекс для синхронизации доступа к очереди
std::condition_variable dataReady;   // Условная переменная для уведомления о наличии данных в очереди

const int numItems = 5;

// Функция, добавляющая элементы в очередь
void producer() {
    for (int i = 0; i < numItems; ++i) {
        {
            std::lock_guard<std::mutex> lock(myMutex);
            myQueue.push(i);
            std::cout << "Produced: " << i << std::endl;
        }  // myMutex автоматически разблокируется после выхода из области видимости lock_guard

        dataReady.notify_one();  // Уведомляем другие потоки о наличии данных в очереди
        std::this_thread::sleep_for(std::chrono::milliseconds(200));  // Эмулируем некоторую работу
    }
}

// Функция, извлекающая элементы из очереди
void consumer(int id) {
    while (true) {
        std::unique_lock<std::mutex> lock(myMutex);
        dataReady.wait(lock, [] { return !myQueue.empty(); });  // Ждем, пока не появятся данные в очереди

        int data = myQueue.front();
        myQueue.pop();
        lock.unlock();  // Разблокируем мьютекс, так как мы больше не используем общие данные
        std::cout << "Consumer " << id << " consumed: " << data << std::endl;

        std::this_thread::sleep_for(std::chrono::milliseconds(500));  // Эмулируем обработку данных
    }
}

int main() {
    std::thread producerThread(producer);

    const int numConsumers = 2;
    std::thread consumerThreads[numConsumers];
    for (int i = 0; i < numConsumers; ++i) {
        consumerThreads[i] = std::thread(consumer, i + 1);
    }

    producerThread.join();
    for (int i = 0; i < numConsumers; ++i) {
        consumerThreads[i].join();
    }

    return 0;
}

```

# OpenMP
OpenMP представляет собой стандарт для языка C++ и других языков программирования, предоставляющий директивы компилятора и библиотечные функции для автоматического параллелизма. Его цель — упростить создание параллельных программ, особенно на многоядерных системах и суперкомпьютерах.

## Директивы OpenMP

OpenMP использует директивы компилятора, предваренные символом `#pragma`, для обозначения участков кода, которые могут выполняться параллельно. Пример директивы:

```cpp
#pragma omp parallel for
for (int i = 0; i < n; ++i) {
    // Параллельный цикл
}
```

## Работа с потоками

OpenMP автоматически управляет созданием и управлением потоками, что упрощает параллельное выполнение кода.

```cpp
#pragma omp parallel
{
    // Код, выполняемый параллельно
}
```

## Распределение итераций цикла

OpenMP предоставляет возможность распределения итераций цикла между потоками, что полезно для равномерного распределения нагрузки.

```cpp
#pragma omp parallel for schedule(dynamic)
for (int i = 0; i < n; ++i) {
    // Параллельный цикл с динамическим расписанием
}
```

## Пример использования OpenMP

```cpp
#include "omp.h"
#include <iostream>
int main() {
  int value = 123;
  #pragma omp parallel 
  {
    #pragma omp atomic
    value++;
    #pragma omp critical (cout)
    {
      std::cout << value << std::endl;
    }
  }
}
```

В данном примере:
- `#pragma omp parallel { ... }`

Это директива OpenMP для создания параллельной секции. Все, что находится внутри блока, будет выполняться параллельно.

- `#pragma omp atomic`

Эта директива гарантирует атомарное выполнение операции. В данном случае, инкрементирование переменной `value` выполняется атомарно, что предотвращает гонки данных (race conditions), когда несколько потоков пытаются изменить значение переменной одновременно.

- `#pragma omp critical (cout) { ... }`

Эта директива определяет критическую секцию, где код внутри блока будет выполняться только одним потоком одновременно. В данном случае, вывод в стандартный поток вывода (cout) происходит в критической секции, чтобы избежать одновременного вывода несколькими потоками..

## Преимущества OpenMP

1. **Простота использования**

Директивы OpenMP легко встраиваются в существующий код, что упрощает добавление параллелизма.

2. **Переносимость кода**

Код, написанный с использованием OpenMP, может быть компилирован и выполняться на различных платформах без изменений.

3. **Эффективность**

OpenMP может автоматически управлять созданием и уничтожением потоков, а также распределением нагрузки.

## Ограничения OpenMP

1. **Ограниченная гибкость**

OpenMP предоставляет удобные средства для добавления параллелизма, но более сложные сценарии могут потребовать использования более низкоуровневых средств.

2. **Не всегда оптимальный контроль** 

В некоторых случаях, для достижения оптимальной производительности, может потребоваться более тонкое управление потоками и ресурсами.

# Параллельные алгоритмы

## Использование стандартных параллельных алгоритмов
Использование стандартных параллельных алгоритмов в C++ является частью стандартной библиотеки `<algorithm>`, начиная с C++17. Эти алгоритмы предоставляют возможность эффективно выполнять операции на контейнерах в параллельной среде, ускоряя выполнение кода на многоядерных системах.

Примеры стандартных параллельных алгоритмов:

1. **`std::for_each` в параллельной форме**
   ```cpp
   #include <algorithm>
   #include <vector>
   #include <iostream>

   int main() {
       std::vector<int> vec = {1, 2, 3, 4, 5};

       // Применение функции к каждому элементу в параллельной форме
       std::for_each(std::execution::par, vec.begin(), vec.end(), [](int& element) {
           element *= 2;
       });

       for (const auto& value : vec) {
           std::cout << value << " ";
       }

       return 0;
   }
   ```

2. **`std::transform` в параллельной форме**
   ```cpp
   #include <algorithm>
   #include <vector>
   #include <iostream>

   int main() {
       std::vector<int> input = {1, 2, 3, 4, 5};
       std::vector<int> output(input.size());

       // Преобразование элементов в параллельной форме
       std::transform(std::execution::par, input.begin(), input.end(), output.begin(), [](int element) {
           return element * 2;
       });

       for (const auto& value : output) {
           std::cout << value << " ";
       }

       return 0;
   }
   ```

3. **`std::sort` в параллельной форме**
   ```cpp
   #include <algorithm>
   #include <vector>
   #include <iostream>

   int main() {
       std::vector<int> vec = {5, 3, 1, 4, 2};

       // Сортировка в параллельной форме
       std::sort(std::execution::par, vec.begin(), vec.end());

       for (const auto& value : vec) {
           std::cout << value << " ";
       }

       return 0;
   }
   ```

В каждом примере указан параметр `std::execution::par`, который указывает на использование параллельной версии алгоритма.

# Как сравнивают параллельные алгоритмы

Сравнение параллельных алгоритмов включает в себя оценку их производительности в многозадачной среде. Для этого используются такие метрики, как ускорение и эффективность.

## Ускорение (Speedup)

Ускорение — это мера того, насколько быстрее параллельная программа выполняется по сравнению с последовательной версией на одном процессоре. Формально ускорение (S) выражается следующим образом:

\[ S = \frac{T_{\text{seq}}}{T_{\text{par}}} \]

Где:
- \( T_{\text{seq}} \) — время выполнения последовательной версии алгоритма,
- \( T_{\text{par}} \) — время выполнения параллельной версии алгоритма.

Ускорение \( S \) больше 1, если параллельная версия быстрее последовательной. Чем выше ускорение, тем эффективнее параллельный алгоритм.

## Эффективность (Efficiency)

Эффективность — это нормализованная мера ускорения относительно количества использованных процессоров (или потоков). Эффективность (E) вычисляется по формуле:

\[ E = \frac{S}{P} \]

Где:
- \( S \) — ускорение,
- \( P \) — количество используемых процессоров (потоков).

Эффективность варьирует от 0 до 1. Если эффективность равна 1, то программа полностью эффективна при использовании всех доступных процессоров. Если эффективность близка к 0, это может указывать на проблемы, такие как избыточные накладные расходы из-за синхронизации или неравномерного распределения работы между потоками.

## Пример

Предположим, что последовательная версия алгоритма выполняется за 100 секунд, а параллельная версия на 4 потоках — за 30 секунд. Тогда ускорение:

\[ S = \frac{100}{30} \approx 3.33 \]

Эффективность при использовании 4 потоков:

\[ E = \frac{3.33}{4} \approx 0.83 \]

Эти значения говорят о том, что параллельная версия алгоритма на 4 потоках в три раза быстрее, чем последовательная, и эффективность составляет примерно 83%, что является хорошим результатом.

# Производительность и масштабируемость

## Измерение производительности

Измерение производительности является важным этапом в разработке параллельных программ. Эффективная оценка производительности помогает выявить узкие места в коде и оптимизировать его для достижения лучшей производительности.

### Инструменты измерения производительности

1. **Профилировщики**

Использование профилировщиков позволяет анализировать время выполнения программы, выявлять функции или участки кода, занимающие больше всего времени. Профилировщики также способны обнаруживать узкие места, которые могут стать целью для параллельных оптимизаций.

2. **Инструменты анализа потоков**

При наличии многопоточности важно анализировать взаимодействие потоков, обнаруживать потенциальные конфликты и оптимизировать синхронизацию.

3. **Инструменты управления памятью**

Оценка использования памяти в параллельной программе важна для предотвращения утечек памяти и оптимизации доступа к общим данным.

## Улучшение производительности

После измерения производительности возможны различные методы улучшения эффективности параллельной программы.

### Оптимизация участков кода

1. **Параллельные алгоритмы**

Замена последовательных алгоритмов на их параллельные аналоги может значительно ускорить выполнение программы, особенно при работе с большими объемами данных.

2. **Разделение задач**

Разбиение больших задач на более мелкие и их распределение между потоками может улучшить масштабируемость и общую производительность.

### Использование эффективных структур данных

1. **Параллельные контейнеры**

Использование специальных параллельных контейнеров, например, `tbb::concurrent_vector` или `std::parallel::vector`, может повысить производительность при параллельном доступе к данным.

2. **Lock-Free и Wait-Free алгоритмы**

Использование алгоритмов, не требующих блокировок, может уменьшить степень синхронизации и улучшить производительность.

### Уменьшение общения между потоками

1. **Уменьшение использования глобальных данных**

Частое обращение к общим глобальным данным может стать узким местом. Минимизация общения между потоками, например, с использованием локальных данных, может улучшить производительность.

2. **Устранение избыточной синхронизации** 

Избегание избыточных блокировок и синхронизаций, которые не являются абсолютно необходимыми, может сократить накладные расходы.


# Линейный конгруэнтный генератор
Линейный конгруэнтный генератор (Linear Congruential Generator, LCG) — это простой тип генератора псевдослучайных чисел, который генерирует последовательность чисел на основе линейного рекуррентного соотношения. Формула для генерации чисел в LCG выглядит следующим образом:

\[X_{n+1} = (a \cdot X_n + c) \mod m\]

Где:
- \(X_n\) — текущее число (или "семя"),
- \(a\) — множитель (положительное целое число),
- \(c\) — приращение (положительное целое число),
- \(m\) — модуль (положительное целое число).

LCG обладает несколькими важными характеристиками:

1. **Периодичность** 

Последовательность, генерируемая LCG, со временем становится периодической. Период — это количество чисел, после которого генератор начинает воспроизводить предыдущие значения.

2. **Зависимость от начального значения** 

Последовательность LCG полностью определяется начальным значением (семянем). Однако, если параметры \(a\), \(c\), и \(m\) выбраны неправильно, генератор может проявлять нежелательные свойства, такие как короткий период или плохое качество случайных чисел.

3. **Простота и быстрота**

LCG легко реализовать и требует небольших вычислительных ресурсов, что делает его привлекательным для простых случаев.

Пример простой реализации LCG:

```cpp
#include <iostream>

class LinearCongruentialGenerator {
private:
    unsigned long long seed;

public:
    LinearCongruentialGenerator(unsigned long long initialSeed)
        : seed(initialSeed) {}

    unsigned long long generate() {
        const unsigned long long a = 6364136223846793005ULL;
        const unsigned long long c = 1ULL << 21;
        const unsigned long long m = (1ULL << 63) - 1;

        seed = (a * seed + c) % m;
        return seed;
    }
};

int main() {
    LinearCongruentialGenerator lcg(12345);

    for (int i = 0; i < 10; ++i) {
        std::cout << lcg.generate() << std::endl;
    }

    return 0;
}
```